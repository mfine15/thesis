% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\date{}

\begin{document}

\hypertarget{header-n0}{%
\section{Towards Practical Private Data Release}\label{header-n0}}

\hypertarget{header-n2}{%
\subsection{Introduction}\label{header-n2}}

In the standard model of differential privacy, analysts submit queries
to a trusted curator, who returns a noisy answer to each in an online
fashion. While simple, this paradigm is suboptimal in a number of ways.
It requires analysts to profoundly change their workflow -\/- instead of
being able to inspect, query, and manipulate data they have access to,
they must now submit queries to a curator without ever being able to
look at the data. Moreover, as {[}TODO cite{]} Dwork notes, this model
gives up \emph{analyst privacy} -\/- the curator is necessarily aware of
each query the analyst makes of the data.

Ideally, the curator would release a \emph{differentially private
synthetic dataset} -\/- a data structure that, while differential
private, "looks like" the true dataset. More formally, given a sensitive
dataset \(\mathcal{X} \in \mathbb{R}^{m\times n}\), we are looking for a
differentially private sanitizer \(M\) such that
\(\tilde{\mathcal{X}} = M(\mathcal{X}) \) approximates \(\mathcal{X}\)
with respect to a class of queries \(Q\):

\[\forall q \in Q : ~~ |q(\mathcal{X}) - q(\tilde{\mathcal{X}})| \leq \alpha\]

for some constant \(\alpha\).

{[}TODO lit review{]}

\hypertarget{header-n14}{%
\subsection{DualQuery }\label{header-n14}}

DualQuery views the problem of private data release as a zero-sum game
between the query player and the data player. The value of the game is
the difference between the query run on the data players move and the
true dataset. In DualQuery's formulation, the query player uses a
no-regret learning algorithm, while the data player finds a best
response using an optimization algorithm.

\hypertarget{header-n26}{%
\subsection{OracleQuery}\label{header-n26}}

OracleQuery generalizes the no-regret adversarial approach of DualQuery
to support any heuristic optimization oracle, while reducing the
oracle-runtime dependence to \(\log |Q|\) rather than \(|Q|\).
Unfortunately, it has a few drawbacks

\begin{itemize}
\item
  Runtime depends linearly on \(1/\delta\), which is infeasible when
  \(\delta\) is cryptographically (\(<10^{-100}\)) small.
\item
  Probabilistic optimization oracle must be able to certify that the
  solution it returns is optimal (though it is allowed to simply not
  return a result with small probability). While this works for certain
  optimization procedures, it is infeasible/impossible for procedures
  like gradient descent. 
\end{itemize}

\hypertarget{header-n20}{%
\subsection{Generative Adversarial Networks}\label{header-n20}}

In a parallel line of research, Generative Adversarial Networks
(Goodfellow 2016) have shown great promise in generative realistic
looking, high dimensionsional images. Quite similar to the DualQuery
approach, a GAN is trained by pairing two deep neural networks, a
generator and a discriminator. The generator aims to generate realistic
samples, while the discriminator tries to distinguish between fake and
real samples.

Beyond standard problems with training GAN's (mode collapse etc), the
primary issue with the GAN formulation is that so far we've not been
able to make any theoretical guarantees about the worst case error (or
even average case) of a query over GAN-generated dataset. This is
extremely important for our scenario, where analysts would like to know
with high probability any result they obtain on the synthetic dataset
would approximately hold on the true dataset. This lack of theoretical
guarantees actually stems from two related problems:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  No guarantee that the converged solution is a global optimum (or
  global nash equilibrium)
\item
  No guarantee that even a global nash equilibria in the \emph{parameter
  space} is really optimal in the \emph{distribution space}. 
\end{enumerate}

\hypertarget{header-n24}{%
\subsubsection{How combine theoretical guarantees with distribution
learning capabilities of GANs}\label{header-n24}}

\end{document}
