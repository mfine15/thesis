### Online Learning with Predictable Sequences

In this paper, Rakhlin and Sridharan describe a method for online learning in a non-convex game with predictable sequences. Typically, we can't make sublinear guarantees on the regret for nonconvex games, but they assume that one opponent follows a somewhat predictable process. 

Specifically, assume that the opponent $M$'s play at time $t$ is a function of each prior play $x_{t-1}...x_1$. This defines a sequences
$$
M_1, M_2(x_1)...M_T(x_1,...,x_{T-1})
$$
Assuming that the opponent doesn't deviate too much from this ideal sequence, they provide sublinear regret bounds. Don't think this is actually that useful though, because this is a really strong guarantee.

### Local Equilibria

If both players in a GAN game used online regret minimization, this would provably converge to an optimal global equlibria. Unfortunately, this is hard in the worst case (Hazan et al 2017). 

We can define an $\epsilon$-approximate *local equilibria* however, where both players do not have much of an incentive to switch to any other strategy within a small neighborhood of their current stategy
$$
\forall x' \in \mathcal{X} : | |x' - x^*|| \leq \eta ~~\land~~ A(x^*,q^*) \leq A(x',q^*) + \epsilon\\
\forall q' \in \mathcal{Q} : | |q' - q^*|| \leq \eta ~~\land~~ A(x^*,q^*) \leq A(x*,q') - \epsilon
$$
**Question:** How can we relate local equilibria to optimality in GAN case